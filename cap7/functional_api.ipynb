{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow info and warning messages\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c326f",
   "metadata": {},
   "source": [
    "Let’s start with something simple: the stack of two layers we used in the previous section. Its Functional API version looks like the following listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbc95af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "#create an input layer (symbolic tensor)\n",
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "#create a layer and call it with the input\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b2afc",
   "metadata": {},
   "source": [
    "the functional API is a way to create models that are more flexible than the Sequential API.\n",
    "\n",
    "they hold more complex topologies, such as multi-input models and multi-output models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7aa0e5",
   "metadata": {},
   "source": [
    "example: \n",
    "\n",
    "Let’s say you’re building a system to rank customer support tickets by priority and route them to the appropriate department. Your model has three inputs:\n",
    "\n",
    "- The title of the ticket (text)\n",
    "- The text of the ticket (text)\n",
    "- The priority of the ticket (categorical)\n",
    "\n",
    "the model has two outputs:\n",
    "- The priority of the ticket (categorical)\n",
    "- The department to route the ticket to (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22d4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "#define model inputs\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "#combine input features into a single tensor\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "#apply a intermidiate layer to recombine input features into richer representation\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "#define model outputs\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "\tnum_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5ca10",
   "metadata": {},
   "source": [
    "### TRAINING A MULTI-INPUT, MULTI-OUTPUT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cd597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - department_accuracy: 0.2633 - department_loss: 63.4675 - loss: 63.7987 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "Epoch 2/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_accuracy: 0.2602 - department_loss: 64.6681 - loss: 64.9993 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "Epoch 3/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_accuracy: 0.2703 - department_loss: 71.5123 - loss: 71.8435 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_accuracy: 0.1352 - department_loss: 97.2811 - loss: 97.6123 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994 \n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=\"rmsprop\",\n",
    "\tloss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "\tmetrics=[[\"mean_absolute_error\"], [\"accuracy\"]]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "\t[title_data, text_body_data, tags_data],\n",
    "\t[priority_data, department_data],\n",
    "\tepochs=3\n",
    ")\n",
    "\n",
    "model.evaluate([title_data, text_body_data, tags_data], [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690b894",
   "metadata": {},
   "source": [
    "You can plot a Functional model as a graph with the plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d26d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pydot\n",
    "import graphviz\n",
    "import tensorflow as tf\n",
    "\n",
    "keras.utils.plot_model( model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea35bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=title, built=True>,\n",
       " <InputLayer name=text_body, built=True>,\n",
       " <InputLayer name=tags, built=True>,\n",
       " <Concatenate name=concatenate_1, built=True>,\n",
       " <Dense name=dense_3, built=True>,\n",
       " <Dense name=priority, built=True>,\n",
       " <Dense name=department, built=True>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee237545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=title>,\n",
       " <KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=text_body>,\n",
       " <KerasTensor shape=(None, 100), dtype=float32, sparse=False, ragged=False, name=tags>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31c75c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 20100), dtype=float32, sparse=False, ragged=False, name=keras_tensor_6>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97933d9a",
   "metadata": {},
   "source": [
    "feature extraction, creating models that reuse intermediate features from another model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854da3fe",
   "metadata": {},
   "source": [
    "Let’s say you want to add another output to the previous model—you want to estimate how long a given issue ticket will take to resolve, a kind of difficulty rating. You could do this via a classification layer over three categories: “quick,” “medium,” and “difficult.” You don’t need to recreate and retrain a model from scratch. You can start from the intermediate features of your previous model, since you have access to them, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a4492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.layers[4].output #layers[4] is the output of the previous model\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model=keras.Model(\n",
    "\tinputs=[title, text_body, tags],\n",
    "\toutputs=[priority, department, difficulty]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad91912",
   "metadata": {},
   "source": [
    "You can train your model in much the same way as you would train a Sequential model, by calling fit() with lists of input and output data. These lists of data should be in the same order as the inputs you passed to the Model constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81fb8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model( new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fb2bb",
   "metadata": {},
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87936f26",
   "metadata": {},
   "source": [
    "The last model-building pattern you should know about is the most advanced one: Model subclassing. You learned in chapter 3 how to subclass the Layer class to create custom layers. Subclassing Model is pretty similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482405d3",
   "metadata": {},
   "source": [
    "Subclassing Model is pretty similar: \n",
    "- In the __init__() method, define the layers the model will use.\n",
    "- In the call() method, define the forward pass of the model, reusing the layers previously created. \n",
    "- Instantiate your subclass, and call it on data to create its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0662345",
   "metadata": {},
   "source": [
    "REWRITING OUR PREVIOUS EXAMPLE AS A SUBCLASSED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931861e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\"\n",
    "        )\n",
    "\n",
    "    #define forward pass in the call method\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features) #output 1\n",
    "        department = self.department_classifier(features) #output 2\n",
    "        return priority, department\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3c89b",
   "metadata": {},
   "source": [
    "Once you’ve defined the model, you can instantiate it. Note that it will only create its weights the first time you call it on some data, much like Layer subclasses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f001937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc2768b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcaa5c4",
   "metadata": {},
   "source": [
    "What, then, is the difference between a Layer subclass and a Model subclass? It’s simple: a “layer” is a building block you use to create models, and a “model” is the top-level object that you will actually train, export for inference, etc. In short, a Model has fit(), evaluate(), and predict() methods. Layers don’t. Other than that, the two classes are virtually identical. (Another difference is that you can save a model to a file on disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbbee0",
   "metadata": {},
   "source": [
    "You can compile and train a Model subclass just like a Sequential or Functional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f830b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2937 - categorical_crossentropy_loss: 31.1573 - loss: 31.4721 - mean_absolute_error: 0.4808 - mean_squared_error_loss: 0.3148\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5664 - categorical_crossentropy_loss: 35.3319 - loss: 35.6525 - mean_absolute_error: 0.4873 - mean_squared_error_loss: 0.3206\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "\n",
    "model.fit({\"title\": title_data,\n",
    "        \"text_body\": text_body_data,\n",
    "        \"tags\":tags_data},\n",
    "        [priority_data, department_data],\n",
    "        epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\":tags_data},\n",
    "                [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict(\n",
    "{\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6f44a",
   "metadata": {},
   "source": [
    "The Model subclassing workflow is the most flexible way to build a model. It enables you to build models that cannot be expressed as directed acyclic graphs of layersimagine, for instance, a model where the call() method uses layers inside a for loop, or even calls them recursively. Anything is possible—you’re in charge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c345d8",
   "metadata": {},
   "source": [
    "Functional and subclassed models are also substantially different in nature. A Functional model is an explicit data structure—a graph of layers, which you can view, inspect, and modify. A subclassed model is a piece of bytecode—a Python class with a call() method that contains raw code. This is the source of the subclassing workflow’s flexibility—you can code up whatever functionality you like—but it introduces new limitations. For instance, because the way layers are connected to each other is hidden inside the body of the call() method, you cannot access that information. Calling summary() will not display layer connectivity, and you cannot plot the model topology via plot_model(). Likewise, if you have a subclassed model, you cannot access the nodes of the graph of layers to do feature extraction because there is simply no graph. Once the model is instantiated, its forward pass becomes a complete black box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d7ceb",
   "metadata": {},
   "source": [
    "### 7.2.4 Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b0bb5",
   "metadata": {},
   "source": [
    "you can use a subclassed layer or model in a Functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a23203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        #se é classficiacao binaria ou multiclasse\n",
    "        if num_classes ==2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\") (inputs)\n",
    "outputs = Classifier(num_classes=10) (features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c419a",
   "metadata": {},
   "source": [
    "Inversely, you can use a Functional model as part of a subclassed layer or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae734b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d1049",
   "metadata": {},
   "source": [
    "### 7.3 Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb49adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2936 - val_accuracy: 0.9565 - val_loss: 0.1471\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1603 - val_accuracy: 0.9679 - val_loss: 0.1124\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1295 - val_accuracy: 0.9746 - val_loss: 0.0961\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.0912  \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28*28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5) (features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\") (features)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28*28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28*28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "        epochs=3,\n",
    "        validation_data=(val_images,val_labels))\n",
    "#compute loss and metrics on new data\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "#compute classification probabilities on new data\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf171a",
   "metadata": {},
   "source": [
    "There are a couple of ways you can customize this simple workflow: \n",
    "- Provide your own custom metrics.\n",
    "- Pass callbacks to the fit() method to schedule actions to be taken at specific points during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be863f81",
   "metadata": {},
   "source": [
    "### 7.3.1 Writing your own metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    #Define the state  variables in the  constructor.\n",
    "    #Like for layers, you  have access to  the add_weight() method.\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "\n",
    "    #implement the state update logic in update_state(). the y_true argument\n",
    "    #is the targets for one batch, while y_pred represents the\n",
    "    # corresponding predicitons from the model.\n",
    "    # sample_weights wont be used here\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    #to match our MNIST modal,we expect categorical predicitons and integer labels\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred) [0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    #You use the result() method to return the current value of the metric:\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    #Meanwhile, you also need to expose a way\n",
    "    #  to reset the metric state without\n",
    "    #  having to reinstantiate it—this\n",
    "    #  enables the same metric objects to be\n",
    "    #  used across different epochs of training\n",
    "    # or across both training and evaluation.\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677470eb",
   "metadata": {},
   "source": [
    "Custom metrics can be used just like built-in ones. Let’s test-drive our own metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2984 - rmse: 0.3652 - val_accuracy: 0.9590 - val_loss: 0.1416 - val_rmse: 0.2493\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1625 - rmse: 0.2666 - val_accuracy: 0.9667 - val_loss: 0.1159 - val_rmse: 0.2254\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1302 - rmse: 0.2393 - val_accuracy: 0.9689 - val_loss: 0.1095 - val_rmse: 0.2152\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.1067 - rmse: 0.2133\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "        epochs=3,\n",
    "        validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d4765",
   "metadata": {},
   "source": [
    "### 7.3.2 Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf122d",
   "metadata": {},
   "source": [
    "A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to fit() and that is called by the model at various points during training. It has access to all the available data about the state of the model and its performance, and it can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4697c",
   "metadata": {},
   "source": [
    "callback examples:\n",
    "- Model checkpointing—Saving the current state of the model at different points during training.\n",
    "- Early stopping—Interrupting training when the model’s performance on a validation set stops improving.\n",
    "- Dynamically adjusting the value of certain parameters during training —Such as the learning rate of the optimizer.\n",
    "- Logging training and validation metrics during training, or visualizing the representations learned by the model as they’re updated—The fit() progress bar that you’re familiar with is in fact a callback!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17aec8",
   "metadata": {},
   "source": [
    "### THE EARLYSTOPPING AND MODELCHECKPOINT CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a15a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2961 - val_accuracy: 0.9546 - val_loss: 0.1558\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1586 - val_accuracy: 0.9683 - val_loss: 0.1121\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1315 - val_accuracy: 0.9723 - val_loss: 0.1054\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1160 - val_accuracy: 0.9741 - val_loss: 0.0989\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1041 - val_accuracy: 0.9736 - val_loss: 0.1013\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0939 - val_accuracy: 0.9773 - val_loss: 0.0965\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0876 - val_accuracy: 0.9745 - val_loss: 0.1049\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0825 - val_accuracy: 0.9788 - val_loss: 0.0908\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0749 - val_accuracy: 0.9794 - val_loss: 0.0912\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0729 - val_accuracy: 0.9799 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bec1b98cb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "callbacks_list = [\n",
    "\tkeras.callbacks.EarlyStopping(\n",
    "\t\tmonitor=\"val_accuracy\",\n",
    "\t\tpatience=2,\n",
    "\t),\n",
    "\t#saves the current weights after every epoch\n",
    "\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\tfilepath=\"checkpoint_path.keras\",\n",
    "\t\tmonitor=\"val_accuracy\",#These two arguments mean you wont  overwrite the model\n",
    "\t\t# file unless val_loss  has improved, which allows you to keep  the best model seen during training.\n",
    "\t\tsave_best_only=True,\n",
    "\t)\n",
    "]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tcallbacks=callbacks_list,\n",
    "\t\tvalidation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d14ba",
   "metadata": {},
   "source": [
    "### 7.3.3 Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44a443",
   "metadata": {},
   "source": [
    "Callbacks are implemented by subclassing the keras.callbacks.Callback class. You can then implement any number of the following transparently named methods, which are called at various points during training:\n",
    "- on_epoch_begin\n",
    "- on_epoch_end\n",
    "- on_batch_begin\n",
    "- on_batch_end\n",
    "- on_train_begin\n",
    "- on_train_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e8998",
   "metadata": {},
   "source": [
    "These methods are all called with a logs argument, which is a dictionary containing information about the previous batch, epoch, or training run—training and validation metrics, and so on. The on_epoch_* and on_batch_* methods also take the epoch or batch index as their first argument (an integer). Here’s a simple example that saves a list of per-batch loss values during training and saves a graph of these values at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e3bac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#example that saves a list of per-batch loss values during training\n",
    "#  and saves a graph of these values at the end of each epoch\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "\n",
    "\tdef on_train_begin(self, logs):\n",
    "\t\tself.per_batch_losses = []\n",
    "\n",
    "\tdef on_batch_end(self, batch, logs):\n",
    "\t\tself.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "\tdef on_epoch_end(self, epoch, logs):\n",
    "\t\tplt.clf()\n",
    "\t\tplt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "\t\t\t\tlabel=\"Training loss for each batch\")\n",
    "\t\tplt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "\t\tplt.ylabel(\"Loss\")\n",
    "\t\tplt.legend()\n",
    "\t\tplt.savefig(f\"plot_at_epoch_{epoch}.png\")\n",
    "\t\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e8b3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2938 - val_accuracy: 0.9573 - val_loss: 0.1478\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1589 - val_accuracy: 0.9667 - val_loss: 0.1140\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1308 - val_accuracy: 0.9722 - val_loss: 0.0997\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.1142 - val_accuracy: 0.9741 - val_loss: 0.0992\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.1044 - val_accuracy: 0.9765 - val_loss: 0.0937\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0926 - val_accuracy: 0.9784 - val_loss: 0.0883\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0863 - val_accuracy: 0.9789 - val_loss: 0.0917\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0829 - val_accuracy: 0.9780 - val_loss: 0.0943\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0753 - val_accuracy: 0.9791 - val_loss: 0.0915\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0725 - val_accuracy: 0.9788 - val_loss: 0.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bec29259a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tcallbacks=[LossHistory()],\n",
    "\t\tvalidation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d7c6b",
   "metadata": {},
   "source": [
    "### 7.3.4 Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c227a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2956 - val_accuracy: 0.9563 - val_loss: 0.1566\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1592 - val_accuracy: 0.9661 - val_loss: 0.1166\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1315 - val_accuracy: 0.9731 - val_loss: 0.0996\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.1146 - val_accuracy: 0.9748 - val_loss: 0.1015\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.1030 - val_accuracy: 0.9751 - val_loss: 0.0978\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0933 - val_accuracy: 0.9757 - val_loss: 0.0941\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0882 - val_accuracy: 0.9788 - val_loss: 0.0873\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0792 - val_accuracy: 0.9791 - val_loss: 0.0849\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0784 - val_accuracy: 0.9770 - val_loss: 0.0954\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0728 - val_accuracy: 0.9791 - val_loss: 0.0922\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-170189316dc145b3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-170189316dc145b3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "\t\tlog_dir=\"logs\"\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tvalidation_data=(val_images, val_labels),\n",
    "\t\tcallbacks=[tensorboard])\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir cap7/logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a82150",
   "metadata": {},
   "source": [
    "Once the model starts running, it will write logs at the target location. If you are running your Python script on a local machine, you can then launch the local TensorBoard server using the following command:  \n",
    "\n",
    "tensorboard --logdir /full_path_to_your_log_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
