{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow info and warning messages\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c326f",
   "metadata": {},
   "source": [
    "Let’s start with something simple: the stack of two layers we used in the previous section. Its Functional API version looks like the following listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbc95af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "#create an input layer (symbolic tensor)\n",
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "#create a layer and call it with the input\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b2afc",
   "metadata": {},
   "source": [
    "the functional API is a way to create models that are more flexible than the Sequential API.\n",
    "\n",
    "they hold more complex topologies, such as multi-input models and multi-output models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7aa0e5",
   "metadata": {},
   "source": [
    "example: \n",
    "\n",
    "Let’s say you’re building a system to rank customer support tickets by priority and route them to the appropriate department. Your model has three inputs:\n",
    "\n",
    "- The title of the ticket (text)\n",
    "- The text of the ticket (text)\n",
    "- The priority of the ticket (categorical)\n",
    "\n",
    "the model has two outputs:\n",
    "- The priority of the ticket (categorical)\n",
    "- The department to route the ticket to (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22d4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "#define model inputs\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "#combine input features into a single tensor\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "#apply a intermidiate layer to recombine input features into richer representation\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "#define model outputs\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "\tnum_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5ca10",
   "metadata": {},
   "source": [
    "### TRAINING A MULTI-INPUT, MULTI-OUTPUT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cd597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - department_accuracy: 0.2633 - department_loss: 63.4675 - loss: 63.7987 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "Epoch 2/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - department_accuracy: 0.2602 - department_loss: 64.6681 - loss: 64.9993 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "Epoch 3/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - department_accuracy: 0.2703 - department_loss: 71.5123 - loss: 71.8435 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_accuracy: 0.1352 - department_loss: 97.2811 - loss: 97.6123 - priority_loss: 0.3312 - priority_mean_absolute_error: 0.4994 \n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=\"rmsprop\",\n",
    "\tloss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "\tmetrics=[[\"mean_absolute_error\"], [\"accuracy\"]]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "\t[title_data, text_body_data, tags_data],\n",
    "\t[priority_data, department_data],\n",
    "\tepochs=3\n",
    ")\n",
    "\n",
    "model.evaluate([title_data, text_body_data, tags_data], [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690b894",
   "metadata": {},
   "source": [
    "You can plot a Functional model as a graph with the plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d26d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pydot\n",
    "import graphviz\n",
    "import tensorflow as tf\n",
    "\n",
    "keras.utils.plot_model( model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea35bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=title, built=True>,\n",
       " <InputLayer name=text_body, built=True>,\n",
       " <InputLayer name=tags, built=True>,\n",
       " <Concatenate name=concatenate_1, built=True>,\n",
       " <Dense name=dense_3, built=True>,\n",
       " <Dense name=priority, built=True>,\n",
       " <Dense name=department, built=True>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee237545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=title>,\n",
       " <KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=text_body>,\n",
       " <KerasTensor shape=(None, 100), dtype=float32, sparse=False, ragged=False, name=tags>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31c75c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 20100), dtype=float32, sparse=False, ragged=False, name=keras_tensor_6>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97933d9a",
   "metadata": {},
   "source": [
    "feature extraction, creating models that reuse intermediate features from another model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854da3fe",
   "metadata": {},
   "source": [
    "Let’s say you want to add another output to the previous model—you want to estimate how long a given issue ticket will take to resolve, a kind of difficulty rating. You could do this via a classification layer over three categories: “quick,” “medium,” and “difficult.” You don’t need to recreate and retrain a model from scratch. You can start from the intermediate features of your previous model, since you have access to them, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a4492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.layers[4].output #layers[4] is the output of the previous model\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model=keras.Model(\n",
    "\tinputs=[title, text_body, tags],\n",
    "\toutputs=[priority, department, difficulty]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad91912",
   "metadata": {},
   "source": [
    "You can train your model in much the same way as you would train a Sequential model, by calling fit() with lists of input and output data. These lists of data should be in the same order as the inputs you passed to the Model constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81fb8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model( new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fb2bb",
   "metadata": {},
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87936f26",
   "metadata": {},
   "source": [
    "The last model-building pattern you should know about is the most advanced one: Model subclassing. You learned in chapter 3 how to subclass the Layer class to create custom layers. Subclassing Model is pretty similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482405d3",
   "metadata": {},
   "source": [
    "Subclassing Model is pretty similar: \n",
    "- In the __init__() method, define the layers the model will use.\n",
    "- In the call() method, define the forward pass of the model, reusing the layers previously created. \n",
    "- Instantiate your subclass, and call it on data to create its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0662345",
   "metadata": {},
   "source": [
    "REWRITING OUR PREVIOUS EXAMPLE AS A SUBCLASSED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931861e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\"\n",
    "        )\n",
    "\n",
    "    #define forward pass in the call method\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features) #output 1\n",
    "        department = self.department_classifier(features) #output 2\n",
    "        return priority, department\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3c89b",
   "metadata": {},
   "source": [
    "Once you’ve defined the model, you can instantiate it. Note that it will only create its weights the first time you call it on some data, much like Layer subclasses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd81c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected CustomModel implementation\n",
    "import tensorflow as tf\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tsuper().__init__(*args, **kwargs)\n",
    "\t\tself.optimizer = None\n",
    "\n",
    "\tdef train_step(self, data):\n",
    "\t\tinputs, targets = data\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tpredictions = self(inputs, training=True)\n",
    "\t\t\tloss = loss_fn(targets, predictions)\n",
    "\t\tgradients = tape.gradient(loss, self.trainable_weights)\n",
    "\t\tself.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "\t\tloss_tracker.update_state(loss)\n",
    "\t\treturn {\"loss\": loss_tracker.result()}\n",
    "\n",
    "\tdef compile(self, optimizer, **kwargs):\n",
    "\t\tsuper().compile(**kwargs)\n",
    "\t\tself.optimizer = optimizer\n",
    "\n",
    "\t#lists metrics that should be reseted across epochs\n",
    "\t@property\n",
    "\tdef metrics(self):\n",
    "\t\treturn [loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "566841de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2900 - val_loss: 0.0000e+00\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.1587 - val_loss: 0.0000e+00\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.1279 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1919882c920>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected usage with proper compile parameters\n",
    "inputs = keras.Input(shape=(28*28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# Complete compile with loss function and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=3, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f001937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc2768b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcaa5c4",
   "metadata": {},
   "source": [
    "What, then, is the difference between a Layer subclass and a Model subclass? It’s simple: a “layer” is a building block you use to create models, and a “model” is the top-level object that you will actually train, export for inference, etc. In short, a Model has fit(), evaluate(), and predict() methods. Layers don’t. Other than that, the two classes are virtually identical. (Another difference is that you can save a model to a file on disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbbee0",
   "metadata": {},
   "source": [
    "You can compile and train a Model subclass just like a Sequential or Functional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f830b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2937 - categorical_crossentropy_loss: 31.1573 - loss: 31.4721 - mean_absolute_error: 0.4808 - mean_squared_error_loss: 0.3148\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5664 - categorical_crossentropy_loss: 35.3319 - loss: 35.6525 - mean_absolute_error: 0.4873 - mean_squared_error_loss: 0.3206\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "\n",
    "model.fit({\"title\": title_data,\n",
    "        \"text_body\": text_body_data,\n",
    "        \"tags\":tags_data},\n",
    "        [priority_data, department_data],\n",
    "        epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\":tags_data},\n",
    "                [priority_data, department_data])\n",
    "\n",
    "priority_preds, department_preds = model.predict(\n",
    "{\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6f44a",
   "metadata": {},
   "source": [
    "The Model subclassing workflow is the most flexible way to build a model. It enables you to build models that cannot be expressed as directed acyclic graphs of layersimagine, for instance, a model where the call() method uses layers inside a for loop, or even calls them recursively. Anything is possible—you’re in charge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c345d8",
   "metadata": {},
   "source": [
    "Functional and subclassed models are also substantially different in nature. A Functional model is an explicit data structure—a graph of layers, which you can view, inspect, and modify. A subclassed model is a piece of bytecode—a Python class with a call() method that contains raw code. This is the source of the subclassing workflow’s flexibility—you can code up whatever functionality you like—but it introduces new limitations. For instance, because the way layers are connected to each other is hidden inside the body of the call() method, you cannot access that information. Calling summary() will not display layer connectivity, and you cannot plot the model topology via plot_model(). Likewise, if you have a subclassed model, you cannot access the nodes of the graph of layers to do feature extraction because there is simply no graph. Once the model is instantiated, its forward pass becomes a complete black box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d7ceb",
   "metadata": {},
   "source": [
    "### 7.2.4 Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b0bb5",
   "metadata": {},
   "source": [
    "you can use a subclassed layer or model in a Functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a23203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        #se é classficiacao binaria ou multiclasse\n",
    "        if num_classes ==2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\") (inputs)\n",
    "outputs = Classifier(num_classes=10) (features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c419a",
   "metadata": {},
   "source": [
    "Inversely, you can use a Functional model as part of a subclassed layer or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae734b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d1049",
   "metadata": {},
   "source": [
    "### 7.3 Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb49adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2951 - val_accuracy: 0.9564 - val_loss: 0.1502\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1584 - val_accuracy: 0.9693 - val_loss: 0.1121\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1314 - val_accuracy: 0.9715 - val_loss: 0.1044\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9729 - loss: 0.0931  \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28*28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5) (features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\") (features)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28*28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28*28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "        epochs=3,\n",
    "        validation_data=(val_images,val_labels))\n",
    "#compute loss and metrics on new data\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "#compute classification probabilities on new data\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf171a",
   "metadata": {},
   "source": [
    "There are a couple of ways you can customize this simple workflow: \n",
    "- Provide your own custom metrics.\n",
    "- Pass callbacks to the fit() method to schedule actions to be taken at specific points during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be863f81",
   "metadata": {},
   "source": [
    "### 7.3.1 Writing your own metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    #Define the state  variables in the  constructor.\n",
    "    #Like for layers, you  have access to  the add_weight() method.\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "\n",
    "    #implement the state update logic in update_state(). the y_true argument\n",
    "    #is the targets for one batch, while y_pred represents the\n",
    "    # corresponding predicitons from the model.\n",
    "    # sample_weights wont be used here\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    #to match our MNIST modal,we expect categorical predicitons and integer labels\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred) [0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "    #You use the result() method to return the current value of the metric:\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    #Meanwhile, you also need to expose a way\n",
    "    #  to reset the metric state without\n",
    "    #  having to reinstantiate it—this\n",
    "    #  enables the same metric objects to be\n",
    "    #  used across different epochs of training\n",
    "    # or across both training and evaluation.\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677470eb",
   "metadata": {},
   "source": [
    "Custom metrics can be used just like built-in ones. Let’s test-drive our own metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2984 - rmse: 0.3652 - val_accuracy: 0.9590 - val_loss: 0.1416 - val_rmse: 0.2493\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1625 - rmse: 0.2666 - val_accuracy: 0.9667 - val_loss: 0.1159 - val_rmse: 0.2254\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1302 - rmse: 0.2393 - val_accuracy: 0.9689 - val_loss: 0.1095 - val_rmse: 0.2152\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.1067 - rmse: 0.2133\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "        epochs=3,\n",
    "        validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d4765",
   "metadata": {},
   "source": [
    "### 7.3.2 Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf122d",
   "metadata": {},
   "source": [
    "A callback is an object (a class instance implementing specific methods) that is passed to the model in the call to fit() and that is called by the model at various points during training. It has access to all the available data about the state of the model and its performance, and it can take action: interrupt training, save a model, load a different weight set, or otherwise alter the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4697c",
   "metadata": {},
   "source": [
    "callback examples:\n",
    "- Model checkpointing—Saving the current state of the model at different points during training.\n",
    "- Early stopping—Interrupting training when the model’s performance on a validation set stops improving.\n",
    "- Dynamically adjusting the value of certain parameters during training —Such as the learning rate of the optimizer.\n",
    "- Logging training and validation metrics during training, or visualizing the representations learned by the model as they’re updated—The fit() progress bar that you’re familiar with is in fact a callback!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17aec8",
   "metadata": {},
   "source": [
    "### THE EARLYSTOPPING AND MODELCHECKPOINT CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a15a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2961 - val_accuracy: 0.9546 - val_loss: 0.1558\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1586 - val_accuracy: 0.9683 - val_loss: 0.1121\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1315 - val_accuracy: 0.9723 - val_loss: 0.1054\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1160 - val_accuracy: 0.9741 - val_loss: 0.0989\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1041 - val_accuracy: 0.9736 - val_loss: 0.1013\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0939 - val_accuracy: 0.9773 - val_loss: 0.0965\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0876 - val_accuracy: 0.9745 - val_loss: 0.1049\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0825 - val_accuracy: 0.9788 - val_loss: 0.0908\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0749 - val_accuracy: 0.9794 - val_loss: 0.0912\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0729 - val_accuracy: 0.9799 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bec1b98cb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "callbacks_list = [\n",
    "\tkeras.callbacks.EarlyStopping(\n",
    "\t\tmonitor=\"val_accuracy\",\n",
    "\t\tpatience=2,\n",
    "\t),\n",
    "\t#saves the current weights after every epoch\n",
    "\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\tfilepath=\"checkpoint_path.keras\",\n",
    "\t\tmonitor=\"val_accuracy\",#These two arguments mean you wont  overwrite the model\n",
    "\t\t# file unless val_loss  has improved, which allows you to keep  the best model seen during training.\n",
    "\t\tsave_best_only=True,\n",
    "\t)\n",
    "]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tcallbacks=callbacks_list,\n",
    "\t\tvalidation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d14ba",
   "metadata": {},
   "source": [
    "### 7.3.3 Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44a443",
   "metadata": {},
   "source": [
    "Callbacks are implemented by subclassing the keras.callbacks.Callback class. You can then implement any number of the following transparently named methods, which are called at various points during training:\n",
    "- on_epoch_begin\n",
    "- on_epoch_end\n",
    "- on_batch_begin\n",
    "- on_batch_end\n",
    "- on_train_begin\n",
    "- on_train_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e8998",
   "metadata": {},
   "source": [
    "These methods are all called with a logs argument, which is a dictionary containing information about the previous batch, epoch, or training run—training and validation metrics, and so on. The on_epoch_* and on_batch_* methods also take the epoch or batch index as their first argument (an integer). Here’s a simple example that saves a list of per-batch loss values during training and saves a graph of these values at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e3bac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#example that saves a list of per-batch loss values during training\n",
    "#  and saves a graph of these values at the end of each epoch\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "\n",
    "\tdef on_train_begin(self, logs):\n",
    "\t\tself.per_batch_losses = []\n",
    "\n",
    "\tdef on_batch_end(self, batch, logs):\n",
    "\t\tself.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "\tdef on_epoch_end(self, epoch, logs):\n",
    "\t\tplt.clf()\n",
    "\t\tplt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "\t\t\t\tlabel=\"Training loss for each batch\")\n",
    "\t\tplt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "\t\tplt.ylabel(\"Loss\")\n",
    "\t\tplt.legend()\n",
    "\t\tplt.savefig(f\"plot_at_epoch_{epoch}.png\")\n",
    "\t\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e8b3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2938 - val_accuracy: 0.9573 - val_loss: 0.1478\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1589 - val_accuracy: 0.9667 - val_loss: 0.1140\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1308 - val_accuracy: 0.9722 - val_loss: 0.0997\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.1142 - val_accuracy: 0.9741 - val_loss: 0.0992\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.1044 - val_accuracy: 0.9765 - val_loss: 0.0937\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0926 - val_accuracy: 0.9784 - val_loss: 0.0883\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0863 - val_accuracy: 0.9789 - val_loss: 0.0917\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0829 - val_accuracy: 0.9780 - val_loss: 0.0943\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0753 - val_accuracy: 0.9791 - val_loss: 0.0915\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0725 - val_accuracy: 0.9788 - val_loss: 0.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bec29259a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tcallbacks=[LossHistory()],\n",
    "\t\tvalidation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d7c6b",
   "metadata": {},
   "source": [
    "### 7.3.4 Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c227a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2974 - val_accuracy: 0.9545 - val_loss: 0.1517\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1598 - val_accuracy: 0.9692 - val_loss: 0.1132\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1325 - val_accuracy: 0.9723 - val_loss: 0.1083\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1124 - val_accuracy: 0.9766 - val_loss: 0.0998\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.1028 - val_accuracy: 0.9765 - val_loss: 0.0952\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0939 - val_accuracy: 0.9768 - val_loss: 0.0936\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0905 - val_accuracy: 0.9755 - val_loss: 0.1009\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0830 - val_accuracy: 0.9786 - val_loss: 0.0876\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.0779 - val_accuracy: 0.9796 - val_loss: 0.0901\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0741 - val_accuracy: 0.9794 - val_loss: 0.0895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20632), started 0:20:52 ago. (Use '!kill 20632' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a7038278988c18e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a7038278988c18e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "\t\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\t\tmetrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "\t\tlog_dir=\"logs\"\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "\t\tepochs=10,\n",
    "\t\tvalidation_data=(val_images, val_labels),\n",
    "\t\tcallbacks=[tensorboard])\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a82150",
   "metadata": {},
   "source": [
    "Once the model starts running, it will write logs at the target location. If you are running your Python script on a local machine, you can then launch the local TensorBoard server using the following command:  \n",
    "\n",
    "tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f54e5b",
   "metadata": {},
   "source": [
    "### 7.4 Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310baae0",
   "metadata": {},
   "source": [
    "### 7.4.1 Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9979e91",
   "metadata": {},
   "source": [
    "Some Keras layers, such as the Dropout layer, have different behaviors during training and during inference (when you use them to generate predictions). Such layers expose a training Boolean argument in their call() method. Calling dropout(inputs, training=True) will drop some activation entries, while calling dropout(inputs, training=False) does nothing. By extension, Functional and Sequential models also expose this training argument in their call() methods. Remember to pass training =True when you call a Keras model during the forward pass! Our forward pass thus becomes predictions = model(inputs, training=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20920a98",
   "metadata": {},
   "source": [
    "In addition, note that when you retrieve the gradients of the weights of your model, you should not use tape.gradients(loss, model.weights), but rather tape .gradients(loss, model.trainable_weights). Indeed, layers and models own two kinds of weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b732155",
   "metadata": {},
   "source": [
    "- Trainable weights—These are meant to be updated via backpropagation to minimize the loss of the model, such as the kernel and bias of a Dense layer.\n",
    "- Non-trainable weights—These are meant to be updated during the forward pass by the layers that own them. For instance, if you wanted a custom layer to keep a counter of how many batches it has processed so far, that information would be stored in a non-trainable weight, and at each batch, your layer would increment the counter by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1632890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tpredictions = model(inputs, training=True)\n",
    "\t\tloss = loss_fn(targets, predictions)\n",
    "\t\tgradients = tape.gradients(loss, model.trainable_weights)\n",
    "\t\toptimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05649087",
   "metadata": {},
   "source": [
    "### 7.4.2 Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35bc03",
   "metadata": {},
   "source": [
    "for each batch of targets and predictions, and then use result() to query the current metric value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2651fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.0\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "result = metric.result()\n",
    "print(f\"result: {result.numpy()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65fa3b",
   "metadata": {},
   "source": [
    "you may also need to track the average of a scalar value, such as the model’s loss. You can do this via the keras.metrics.Mean metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a978fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.0\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "\tmean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31541667",
   "metadata": {},
   "source": [
    "7.4.3 A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66185c0d",
   "metadata": {},
   "source": [
    "Let’s combine the forward pass, backward pass, and metrics tracking into a fit()-like training step function that takes a batch of data and targets and returns the logs that would get displayed by the fit() progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ee83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tpredictions = model(inputs, training=True)\n",
    "\t\tloss = loss_fn(targets, predictions)\n",
    "\tgradients = tape.gradient(loss, model.trainable_weights)\n",
    "\toptimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\tlogs = {}\n",
    "\tfor metric in metrics:\n",
    "\t\tmetric.update_state(targets, predictions)\n",
    "\t\tlogs[metric.name] = metric.result()\n",
    "\tloss_tracking_metric.update_state(loss)\n",
    "\tlogs[\"loss\"] = loss_tracking_metric.result()\n",
    "\treturn logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b1c24",
   "metadata": {},
   "source": [
    "We will need to reset the state of our metrics at the start of each epoch and before running evaluation. Here’s a utility function to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43259253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "\tfor metric in metrics:\n",
    "\t\tmetric.reset_state()\n",
    "\tloss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55c4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'sparse_categorical_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.9146199822425842>, 'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.29007312655448914>}\n",
      "sparse_categorical_accuracy: 0.9146\n",
      "loss: 0.2901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m reset_metrics()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m training_dataset:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \tlogs = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m logs.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(inputs, targets)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_step\u001b[39m(inputs, targets):\n\u001b[32m     10\u001b[39m \t\u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \t\tpredictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \t\tloss = loss_fn(targets, predictions)\n\u001b[32m     13\u001b[39m \tgradients = tape.gradient(loss, model.trainable_weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:183\u001b[39m, in \u001b[36mFunctional.call\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m             backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\ops\\function.py:206\u001b[39m, in \u001b[36mFunction._run_through_graph\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    204\u001b[39m     operation = \u001b[38;5;28mself\u001b[39m._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     outputs = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:644\u001b[39m, in \u001b[36moperation_fn.<locals>.call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    639\u001b[39m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[33m\"\u001b[39m\u001b[33m_call_context_args\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    640\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m     ):\n\u001b[32m    642\u001b[39m         kwargs[name] = value\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:151\u001b[39m, in \u001b[36mDense.call\u001b[39m\u001b[34m(self, inputs, training)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     x = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m         x = ops.add(x, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:4211\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m   4209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m   4210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Matmul().symbolic_call(x1, x2)\n\u001b[32m-> \u001b[39m\u001b[32m4211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:520\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    518\u001b[39m     output_type = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    519\u001b[39m x1 = tf.cast(x1, compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m x2 = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_combined_batch_dimensions\u001b[39m(a, b, output_shape, fn_3d):\n\u001b[32m    523\u001b[39m     a_sparse = \u001b[38;5;28misinstance\u001b[39m(a, tf.SparseTensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1012\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(x, dtype, name)\u001b[39m\n\u001b[32m   1006\u001b[39m   x = indexed_slices.IndexedSlices(values_cast, x.indices, x.dense_shape)\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1008\u001b[39m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[32m   1009\u001b[39m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[32m   1010\u001b[39m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[32m   1011\u001b[39m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m   x = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m x.dtype.is_complex \u001b[38;5;129;01mand\u001b[39;00m base_type.is_floating:\n\u001b[32m   1014\u001b[39m     logging.warn(\n\u001b[32m   1015\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1016\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.  This will \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdiscard the imaginary part and may not be what you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mintended.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:736\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    735\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    207\u001b[39m overload = \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33m__tf_tensor__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[32m    212\u001b[39m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[32m    213\u001b[39m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[32m    214\u001b[39m   ret = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:84\u001b[39m, in \u001b[36mVariable.__tf_tensor__\u001b[39m\u001b[34m(self, dtype, name)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[39m, in \u001b[36mconvert_to_tensor_v2_with_dispatch\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m.tf_export(\u001b[33m\"\u001b[39m\u001b[33mconvert_to_tensor\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[32m     99\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    100\u001b[39m ) -> tensor_lib.Tensor:\n\u001b[32m    101\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[33;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[39m, in \u001b[36mconvert_to_tensor_v2\u001b[39m\u001b[34m(value, dtype, dtype_hint, name)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_hint\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2378\u001b[39m, in \u001b[36m_dense_var_to_tensor\u001b[39m\u001b[34m(var, dtype, name, as_ref)\u001b[39m\n\u001b[32m   2377\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_dense_var_to_tensor\u001b[39m(var, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m, as_ref=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dense_var_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1624\u001b[39m, in \u001b[36mBaseResourceVariable._dense_var_to_tensor\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1622\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_value().op.inputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:658\u001b[39m, in \u001b[36mBaseResourceVariable.value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    656\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cached_value\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:843\u001b[39m, in \u001b[36mBaseResourceVariable._read_variable_op\u001b[39m\u001b[34m(self, no_copy)\u001b[39m\n\u001b[32m    841\u001b[39m       result = read_and_set_handle(no_copy)\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m   result = \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly():\n\u001b[32m    846\u001b[39m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[32m    847\u001b[39m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[32m    848\u001b[39m   record.record_operation(\n\u001b[32m    849\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mReadVariableOp\u001b[39m\u001b[33m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m.handle],\n\u001b[32m    850\u001b[39m       backward_function=\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[32m    851\u001b[39m       forward_function=\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:833\u001b[39m, in \u001b[36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[39m\u001b[34m(no_copy)\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat.forward_compatible(\u001b[32m2022\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m):\n\u001b[32m    832\u001b[39m   gen_resource_variable_ops.disable_copy_on_read(\u001b[38;5;28mself\u001b[39m.handle)\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m result = \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m._dtype, \u001b[38;5;28mself\u001b[39m.handle, result)\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:534\u001b[39m, in \u001b[36mread_variable_op\u001b[39m\u001b[34m(resource, dtype, name)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    533\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReadVariableOp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    537\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "\t(train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "\n",
    "for epoch in range(3):\n",
    "\treset_metrics()\n",
    "\tfor inputs_batch, targets_batch in training_dataset:\n",
    "\t\tlogs = train_step(inputs_batch, targets_batch)\n",
    "\tprint(f\"Epoch {epoch}: {logs}\")\n",
    "\tfor key, value in logs.items():\n",
    "\t\tprint(f\"{key}: {value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb105a8",
   "metadata": {},
   "source": [
    "And here’s the evaluation loop: a simple for loop that repeatedly calls a test_step() function, which processes a single batch of data. The test_step() function is just a subset of the logic of train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e87949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "val_sparse_categorical_accuracy: 0.0596\n",
      "val_loss: 2.3579\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "\tpredictions = model(inputs, training=False)\n",
    "\tloss = loss_fn(targets, predictions)\n",
    "\tlogs = {}\n",
    "\tfor metric in metrics:\n",
    "\t\tmetric.update_state(targets, predictions)\n",
    "\t\tlogs[\"val_\" + metric.name] = metric.result()\n",
    "\tloss_tracking_metric.update_state(loss)\n",
    "\tlogs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "\treturn logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "\tlogs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "\tprint(f\"{key}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6229f7",
   "metadata": {},
   "source": [
    "Congrats—you’ve just reimplemented fit() and evaluate()! Or almost: fit() and evaluate() support many more features, including large-scale distributed computation, which requires a bit more work. It also includes several key performance optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b86861",
   "metadata": {},
   "source": [
    "### 7.4.4 Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2657581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "val_sparse_categorical_accuracy: 0.9684\n",
      "val_loss: 0.1181\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "\tpredictions = model(inputs, training=False)\n",
    "\tloss = loss_fn(targets, predictions)\n",
    "\n",
    "\tlogs = {}\n",
    "\tfor metric in metrics:\n",
    "\t\tmetric.update_state(targets, predictions)\n",
    "\t\tlogs[\"val_\" + metric.name] = metric.result()\n",
    "\tloss_tracking_metric.update_state(loss)\n",
    "\tlogs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "\treturn logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "\tlogs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "\tprint(f\"{key}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5538c",
   "metadata": {},
   "source": [
    "@tf.function é aconselhavel quando o modelo já está otimizado e não precisa ser mais alterado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0455e",
   "metadata": {},
   "source": [
    "### 7.4.5 leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3247354",
   "metadata": {},
   "source": [
    "- We create a new class that subclasses keras.Model.\n",
    "- We override the method train_step(self, data). Its contents are nearly identical to what we used in the previous section. It returns a dictionary mapping metric names (including the loss) to their current values.\n",
    "- We implement a metrics property that tracks the model’s Metric instances. This enables the model to automatically call reset_state() on the model’s metrics at the start of each epoch and at the start of a call to evaluate(), so you don’t have to do it by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0567ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Add this import\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.optimizer = None  # Store optimizer here\n",
    "\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))  # Use self.optimizer\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    def compile(self, optimizer, **kwargs):  # Add custom compile method\n",
    "        super().compile(**kwargs)\n",
    "        self.optimizer = optimizer  # Store the optimizer\n",
    "\n",
    "    #lists metrics that should be reseted across epochs\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12a1940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.2779\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.1496\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x191826dd9d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28*28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\") (features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7888c",
   "metadata": {},
   "source": [
    "- This pattern does not prevent you from building models with the Functional API. You can do this whether you’re building Sequential models, Functional API models, or subclassed models.\n",
    "- You don’t need to use a @tf.function decorator when you override train_ step—the framework does it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910371ee",
   "metadata": {},
   "source": [
    "Now, what about metrics, and what about configuring the loss via compile()? After you’ve called compile(), you get access to the following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7590b",
   "metadata": {},
   "source": [
    "- self.compiled_loss—The loss function you passed to compile().\n",
    "-  self.compiled_metrics—A wrapper for the list of metrics you passed, which allows you to call self.compiled_metrics.update_state() to update all of your metrics at once.\n",
    "- self.metrics—The actual list of metrics you passed to compile(). Note that it also includes a metric that tracks the loss, similar to what we did manually with our loss_tracking_metric earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a38767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "\tdef train_step(self, data):\n",
    "\t\tinputs, targets = data\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tpredictions = self(inputs, training=True)\n",
    "\t\t\tloss = self.compiled_loss(targets, predictions)\n",
    "\t\tgradients = tape.gradient(loss, self.trainable_weights)\n",
    "\t\tself.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\t\t#update models metrics\n",
    "\t\tself.compiled_metrics.update_state(targets, predictions)\n",
    "\t\t#return metric values in a dictionary\n",
    "\t\treturn {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51242fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:673: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ryanz\\estudo-ufal\\dl\\DeepLearningWithPython\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:648: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - sparse_categorical_accuracy: 0.9184 - loss: 0.1000\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - sparse_categorical_accuracy: 0.9556 - loss: 0.1000\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - sparse_categorical_accuracy: 0.9641 - loss: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x191826875f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28*28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\") (features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "\t\t\tloss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "\t\t\tmetrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85af37",
   "metadata": {},
   "source": [
    "## sumary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874612a3",
   "metadata": {},
   "source": [
    "- Keras offers a spectrum of different workflows, based on the principle of progressive disclosure of complexity. They all smoothly inter-operate together.\n",
    "- You can build models via the Sequential class, via the Functional API, or by subclassing the Model class. Most of the time, you’ll be using the Functional API.\n",
    "- The simplest way to train and evaluate a model is via the default fit() and evaluate() methods.\n",
    "-  Keras callbacks provide a simple way to monitor models during your call to fit() and automatically take action based on the state of the model.\n",
    "- You can also fully take control of what fit() does by overriding the train_ step() method.\n",
    "- Beyond fit(), you can also write your own training loops entirely from scratch. This is useful for researchers implementing brand-new training algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
