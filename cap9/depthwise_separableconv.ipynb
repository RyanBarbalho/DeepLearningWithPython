{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10773f59",
   "metadata": {},
   "source": [
    "This layer performs a spatial convolution on each channel of its input, independently, before mixing output channels via a pointwise convolution (a 1 × 1 convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b66f01",
   "metadata": {},
   "source": [
    "This is equivalent to separating the learning of spatial features and the learning of channel-wise features. In much the same way that convolution relies on the assumption that the patterns in images are not tied to specific locations, depthwise separable convolution relies on the assumption that spatial locations in intermediate activations are highly correlated, but different channels are highly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c7e88",
   "metadata": {},
   "source": [
    "## 9.3.5 Putting it together: A mini Xception-like model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2980d",
   "metadata": {},
   "source": [
    "here are the convnet architecture principles you’ve learned so far:\n",
    "- Your model should be organized into repeated blocks of layers, usually made of multiple convolution layers and a max pooling layer.\n",
    "- The number of filters in your layers should increase as the size of the spatial feature maps decreases.\n",
    "- Deep and narrow is better than broad and shallow.\n",
    "- Introducing residual connections around blocks of layers helps you train deeper networks.\n",
    "- It can be beneficial to introduce batch normalization layers after your convolution layers.\n",
    "- It can be beneficial to replace Conv2D layers with SeparableConv2D layers, which are more parameter-efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011e735",
   "metadata": {},
   "source": [
    "### apply this to dogs vs cats example:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
