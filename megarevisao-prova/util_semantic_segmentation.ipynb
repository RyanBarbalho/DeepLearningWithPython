{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f636501",
   "metadata": {},
   "source": [
    "# üéØ Guia Pr√°tico - Segmenta√ß√£o Sem√¢ntica\n",
    "## Para Prova Pr√°tica de Deep Learning\n",
    "\n",
    "Este notebook cont√©m templates e exemplos prontos para usar em provas pr√°ticas de segmenta√ß√£o sem√¢ntica de imagens.\n",
    "\n",
    "### O que √© Segmenta√ß√£o Sem√¢ntica?\n",
    "- **Classifica√ß√£o pixel a pixel**: Cada pixel da imagem √© classificado em uma categoria\n",
    "- **Exemplo**: Separar foreground (gato/cachorro) de background em uma imagem\n",
    "- **Aplica√ß√µes**: Remo√ß√£o de fundo, segmenta√ß√£o m√©dica, detec√ß√£o de objetos, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd243a",
   "metadata": {},
   "source": [
    "## üìö 1. IMPORTS ESSENCIAIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac264686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports b√°sicos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import random\n",
    "\n",
    "# TensorFlow/Keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.utils import load_img, img_to_array, array_to_img\n",
    "\n",
    "# Para visualiza√ß√£o\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8b4a0",
   "metadata": {},
   "source": [
    "## üì• 2. DOWNLOAD E CARREGAMENTO DE DADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o para baixar e extrair Oxford-IIIT Pets Dataset\n",
    "def download_pets_dataset(data_dir=\"data\"):\n",
    "    \"\"\"\n",
    "    Baixa e extrai o dataset Oxford-IIIT Pets para segmenta√ß√£o sem√¢ntica\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # URLs do dataset\n",
    "    images_url = 'http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz'\n",
    "    annotations_url = 'http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz'\n",
    "    \n",
    "    print(\"üì• Baixando images.tar.gz...\")\n",
    "    images_path = os.path.join(data_dir, 'images.tar.gz')\n",
    "    urllib.request.urlretrieve(images_url, images_path)\n",
    "    \n",
    "    print(\"üì• Baixando annotations.tar.gz...\")\n",
    "    annotations_path = os.path.join(data_dir, 'annotations.tar.gz')\n",
    "    urllib.request.urlretrieve(annotations_url, annotations_path)\n",
    "    \n",
    "    # Extrair arquivos\n",
    "    print(\"üì¶ Extraindo images.tar.gz...\")\n",
    "    with tarfile.open(images_path, 'r:gz') as tar:\n",
    "        tar.extractall(data_dir)\n",
    "    \n",
    "    print(\"üì¶ Extraindo annotations.tar.gz...\")\n",
    "    with tarfile.open(annotations_path, 'r:gz') as tar:\n",
    "        tar.extractall(data_dir)\n",
    "    \n",
    "    print(\"‚úÖ Download e extra√ß√£o conclu√≠dos!\")\n",
    "    return data_dir\n",
    "\n",
    "# Executar: download_pets_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o para preparar caminhos de imagens e m√°scaras\n",
    "def prepare_dataset_paths(input_dir, target_dir):\n",
    "    \"\"\"\n",
    "    Prepara listas de caminhos de imagens e m√°scaras correspondentes\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Diret√≥rio com imagens originais\n",
    "        target_dir: Diret√≥rio com m√°scaras de segmenta√ß√£o\n",
    "    \n",
    "    Returns:\n",
    "        input_img_paths: Lista de caminhos das imagens\n",
    "        target_img_paths: Lista de caminhos das m√°scaras\n",
    "    \"\"\"\n",
    "    # Obter todas as imagens JPG\n",
    "    input_img_paths = sorted(glob.glob(os.path.join(input_dir, \"*.jpg\")))\n",
    "    \n",
    "    # Criar caminhos correspondentes das m√°scaras\n",
    "    target_img_paths = []\n",
    "    for img_path in input_img_paths:\n",
    "        filename = os.path.basename(img_path)\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        mask_path = os.path.join(target_dir, name_without_ext + \".png\")\n",
    "        target_img_paths.append(mask_path)\n",
    "    \n",
    "    print(f\"‚úÖ Encontradas {len(input_img_paths)} imagens\")\n",
    "    print(f\"üìÅ Primeiras 3 imagens: {input_img_paths[:3]}\")\n",
    "    print(f\"üìÅ Primeiras 3 m√°scaras: {target_img_paths[:3]}\")\n",
    "    \n",
    "    return input_img_paths, target_img_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o para carregar e pr√©-processar dataset completo\n",
    "def load_segmentation_dataset(input_img_paths, target_img_paths, img_size=(200, 200), \n",
    "                             val_split=0.15, shuffle_seed=1337):\n",
    "    \"\"\"\n",
    "    Carrega dataset completo de segmenta√ß√£o sem√¢ntica\n",
    "    \n",
    "    Args:\n",
    "        input_img_paths: Lista de caminhos das imagens\n",
    "        target_img_paths: Lista de caminhos das m√°scaras\n",
    "        img_size: Tamanho para redimensionar (altura, largura)\n",
    "        val_split: Propor√ß√£o para valida√ß√£o (ex: 0.15 = 15%)\n",
    "        shuffle_seed: Seed para embaralhamento\n",
    "    \n",
    "    Returns:\n",
    "        train_input_imgs, train_targets, val_input_imgs, val_targets\n",
    "    \"\"\"\n",
    "    # Embaralhar mantendo correspond√™ncia\n",
    "    random.Random(shuffle_seed).shuffle(input_img_paths)\n",
    "    random.Random(shuffle_seed).shuffle(target_img_paths)\n",
    "    \n",
    "    # Fun√ß√µes auxiliares\n",
    "    def path_to_input_image(path):\n",
    "        return img_to_array(load_img(path, target_size=img_size))\n",
    "    \n",
    "    def path_to_target(path):\n",
    "        img = img_to_array(\n",
    "            load_img(path, target_size=img_size, color_mode=\"grayscale\")\n",
    "        )\n",
    "        img = img.astype(\"uint8\") - 1  # Labels: 0, 1, 2 (foreground, background, contour)\n",
    "        return img\n",
    "    \n",
    "    # Carregar todas as imagens\n",
    "    num_imgs = len(input_img_paths)\n",
    "    input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
    "    targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
    "    \n",
    "    print(f\"üìä Carregando {num_imgs} imagens...\")\n",
    "    for i in range(num_imgs):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  Processadas {i + 1}/{num_imgs} imagens...\")\n",
    "        input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
    "        targets[i] = path_to_target(target_img_paths[i])\n",
    "    \n",
    "    # Dividir em treino e valida√ß√£o\n",
    "    num_val_samples = int(num_imgs * val_split)\n",
    "    train_input_imgs = input_imgs[:-num_val_samples]\n",
    "    train_targets = targets[:-num_val_samples]\n",
    "    val_input_imgs = input_imgs[-num_val_samples:]\n",
    "    val_targets = targets[-num_val_samples:]\n",
    "    \n",
    "    print(f\"‚úÖ Dataset carregado:\")\n",
    "    print(f\"   Treino: {len(train_input_imgs)} imagens\")\n",
    "    print(f\"   Valida√ß√£o: {len(val_input_imgs)} imagens\")\n",
    "    \n",
    "    return train_input_imgs, train_targets, val_input_imgs, val_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc8f28",
   "metadata": {},
   "source": [
    "## üèóÔ∏è 3. MODELOS DE SEGMENTA√á√ÉO SEM√ÇNTICA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5a9b0",
   "metadata": {},
   "source": [
    "### üîç Arquitetura U-Net Style\n",
    "\n",
    "**Conceito Principal:**\n",
    "- **Encoder (Downsampling)**: Reduz tamanho, aumenta filtros (captura features)\n",
    "- **Decoder (Upsampling)**: Aumenta tamanho, reduz filtros (reconstr√≥i m√°scara)\n",
    "\n",
    "**Por que n√£o usar MaxPooling?**\n",
    "- MaxPooling perde informa√ß√£o de localiza√ß√£o espacial\n",
    "- Em segmenta√ß√£o, precisamos manter localiza√ß√£o precisa\n",
    "- **Solu√ß√£o**: Usar convolu√ß√µes com `strides=2` (downsample) e `Conv2DTranspose` com `strides=2` (upsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• TEMPLATE 1: Modelo b√°sico de segmenta√ß√£o sem√¢ntica (U-Net style)\n",
    "def create_segmentation_model(img_size, num_classes):\n",
    "    \"\"\"\n",
    "    Cria modelo b√°sico para segmenta√ß√£o sem√¢ntica\n",
    "    \n",
    "    Args:\n",
    "        img_size: Tupla (altura, largura) da imagem\n",
    "        num_classes: N√∫mero de classes (ex: 3 para foreground/background/contour)\n",
    "    \n",
    "    Returns:\n",
    "        Modelo Keras compilado\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "    \n",
    "    # Rescalar imagens para [0, 1]\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    \n",
    "    # ENCODER (Downsampling) - Captura features\n",
    "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    # DECODER (Upsampling) - Reconstr√≥i m√°scara\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    # Camada final: classifica√ß√£o por pixel\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üî• TEMPLATE 2: Modelo mais profundo (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template de modelo mais profundo (para imagens maiores ou problemas mais complexos)\n",
    "def create_deep_segmentation_model(img_size, num_classes):\n",
    "    \"\"\"Modelo mais profundo com mais camadas\"\"\"\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    \n",
    "    # ENCODER mais profundo\n",
    "    x = layers.Conv2D(32, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    \n",
    "    # DECODER\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "    \n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efc770",
   "metadata": {},
   "source": [
    "## üé® 4. VISUALIZA√á√ÉO DE M√ÅSCARAS E RESULTADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b992603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o para visualizar m√°scaras de segmenta√ß√£o\n",
    "def display_target(target_array):\n",
    "    \"\"\"\n",
    "    Visualiza uma m√°scara de segmenta√ß√£o (normalizada para visualiza√ß√£o)\n",
    "    \n",
    "    Args:\n",
    "        target_array: Array com valores 0, 1, 2 (foreground, background, contour)\n",
    "    \"\"\"\n",
    "    # Converter: (0,1,2) -> (0, 127, 254) para visualiza√ß√£o\n",
    "    normalized_array = (target_array.astype(\"uint8\") - 1) * 127\n",
    "    if len(normalized_array.shape) == 3:\n",
    "        normalized_array = normalized_array[:, :, 0]\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(normalized_array, cmap='gray')\n",
    "    plt.title(\"Segmentation Mask\")\n",
    "\n",
    "# Exemplo de uso:\n",
    "# display_target(targets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o para visualizar predi√ß√µes do modelo\n",
    "def display_mask(pred_mask):\n",
    "    \"\"\"\n",
    "    Visualiza m√°scara predita pelo modelo\n",
    "    \n",
    "    Args:\n",
    "        pred_mask: Array de predi√ß√£o com shape (H, W, num_classes) ou (H, W)\n",
    "    \"\"\"\n",
    "    # Se for tensor com m√∫ltiplas classes, pegar argmax\n",
    "    if len(pred_mask.shape) == 3:\n",
    "        mask = np.argmax(pred_mask,ÊïôËÇ≤‰∏é=-1)\n",
    "    else:\n",
    "        mask = pred_mask\n",
    "    \n",
    "    # Normalizar para visualiza√ß√£o: (0,1,2) -> (0, 127, 254)\n",
    "    mask = mask * 127\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3086075",
   "metadata": {},
   "source": [
    "## üöÄ 5. WORKFLOW COMPLETO DE TREINAMENTO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10787c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Workflow completo de treinamento de segmenta√ß√£o sem√¢ntica\n",
    "def complete_segmentation_workflow(img_size=(200, 200), num_classes=3, epochs=50, batch_size=64):\n",
    "    \"\"\"\n",
    "    Workflow completo para treinamento de modelo de segmenta√ß√£o sem√¢ntica\n",
    "    \n",
    "    Passos:\n",
    "    1. Baixar dataset (se necess√°rio)\n",
    "    2. Preparar caminhos\n",
    "    3. Carregar dados\n",
    "    4. Criar modelo\n",
    "    5. Compilar\n",
    "    6. Treinar\n",
    "    7. Avaliar e visualizar\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Preparar caminhos (assumindo que dataset j√° foi baixado)\n",
    "    input_dir = \"data/images\"\n",
    "    target_dir = \"data/annotations/trimaps\"\n",
    "    input_img_paths, target_img_paths = prepare_dataset_paths(input_dir, target_dir)\n",
    "    \n",
    "    # 2. Carregar dataset\n",
    "    train_input_imgs, train_targets, val_input_imgs, val_targets = load_segmentation_dataset(\n",
    "        input_img_paths, target_img_paths, img_size=img_size\n",
    "    )\n",
    "    \n",
    "    # 3. Criar modelo\n",
    "    model = create_segmentation_model(img_size, num_classes)\n",
    "    model.summary()\n",
    "    \n",
    "    # 4. Compilar\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "    \n",
    "    # 5. Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"segmentation_model.keras\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\"\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 6. Treinar\n",
    "    print(\"üöÄ Iniciando treinamento...\")\n",
    "    history = model.fit(\n",
    "        train_input_imgs, train_targets,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(val_input_imgs, val_targets),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # 7. Visualizar resultados de algumas imagens\n",
    "    print(\"\\nüìä Visualizando resultados...\")\n",
    "    model_best = keras.models.load_model(\"segmentation_model.keras\")\n",
    "    \n",
    "    # Visualizar algumas predi√ß√µes\n",
    "    for i in range(min(3, len(val_input_imgs))):\n",
    "        test_image = val_input_imgs[i]\n",
    "        true_mask = val_targets[i]\n",
    "        \n",
    "        # Fazer predi√ß√£o\n",
    "        pred_mask = model_best.predict(np.expand_dims(test_image, axis=0))[0]\n",
    "        \n",
    "        # Visualizar\n",
    "        compare_segmentation(test_image, true_mask, pred_mask, title_prefix=f\"Exemplo {i+1}: \")\n",
    "    \n",
    "    # 8. Plotar hist√≥rico\n",
    "    epochs_range = range(1, len(history.history[\"loss\"]) + 1)\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs_range, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return model_best, history\n",
    "\n",
    "# Executar: model, history = complete_segmentation_workflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f0ecc",
   "metadata": {},
   "source": [
    "## üìã 6. DICAS R√ÅPIDAS PARA PROVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30979bee",
   "metadata": {},
   "source": [
    "### ‚ö° Comandos Essenciais\n",
    "\n",
    "```python\n",
    "# 1. Verificar shapes dos dados\n",
    "print(\"Input shape:\", train_input_imgs.shape)  # (N, H, W, 3)\n",
    "print(\"Target shape:\", train_targets.shape)    # (N, H, W, 1)\n",
    "\n",
    "# 2. Verificar valores das m√°scaras\n",
    "print(\"Valores √∫nicos na m√°scara:\", np.unique(train_targets))  # Deve ser [0, 1, 2]\n",
    "\n",
    "# 3. Fazer predi√ß√£o em uma imagem\n",
    "pred = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
    "predicted_mask = np.argmax(pred, axis=-1)\n",
    "\n",
    "# 4. Verificar shape da sa√≠da\n",
    "print(\"Output shape:\", model.output_shape)  # Deve ser (None, H, W, num_classes)\n",
    "```\n",
    "\n",
    "### üéØ Checklist para Prova\n",
    "\n",
    "- [ ] Dataset carregado corretamente (imagens e m√°scaras)\n",
    "- [ ] M√°scaras t√™m valores corretos (0, 1, 2 para 3 classes)\n",
    "- [ ] Modelo criado com Encoder-Decoder (Conv2D + Conv2DTranspose)\n",
    "- [ ] √öltima camada usa `Conv2D(num_classes, activation=\"softmax\")`\n",
    "- [ ] Loss: `sparse_categorical_crossentropy` (para targets inteiros)\n",
    "- [ ] Modelo compilado e treinado\n",
    "- [ ] Resultados visualizados corretamente\n",
    "\n",
    "### üîß Troubleshooting Comum\n",
    "\n",
    "**Erro: Shape mismatch**\n",
    "- Verificar se input_shape do modelo corresponde ao tamanho das imagens\n",
    "- Verificar se num_classes corresponde ao n√∫mero de classes nas m√°scaras\n",
    "\n",
    "**Erro: Loss n√£o diminui**\n",
    "- Verificar se m√°scaras est√£o normalizadas corretamente (0, 1, 2)\n",
    "- Tentar learning rate menor\n",
    "- Verificar se dados est√£o sendo carregados corretamente\n",
    "\n",
    "**Predi√ß√µes muito ruins**\n",
    "- Verificar se modelo tem camadas suficientes\n",
    "- Aumentar n√∫mero de √©pocas\n",
    "- Verificar overfitting (val_loss > train_loss)\n",
    "\n",
    "### üí° Diferen√ßas Importantes: Classifica√ß√£o vs Segmenta√ß√£o\n",
    "\n",
    "| Classifica√ß√£o | Segmenta√ß√£o |\n",
    "|--------------|-------------|\n",
    "| Output: (batch, num_classes) | Output: (batch, H, W, num_classes) |\n",
    "| Usa MaxPooling | Usa Conv2D com strides=2 |\n",
    "| Flatten + Dense | Conv2DTranspose para upsampling |\n",
    "| Categorical Crossentropy | Sparse Categorical Crossentropy |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Fun√ß√£o completa para comparar imagem original, m√°scara verdadeira e predi√ß√£o\n",
    "def compare_segmentation(image, true_mask, pred_mask=None, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Visualiza imagem original, m√°scara verdadeira e predi√ß√£o lado a lado\n",
    "    \n",
    "    Args:\n",
    "        image: Imagem original (array)\n",
    "        true_mask: M√°scara verdadeira (ground truth)\n",
    "        pred_mask: M√°scara predita (opcional)\n",
    "    \"\"\"\n",
    "    num_cols = 3 if pred_mask is not None else 2\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Imagem original\n",
    "    plt.subplot(1, num_cols, 1)\n",
    "    plt.axis(\"off\")\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        plt.imshow(image.astype(\"uint8\"))\n",
    "    else:\n",
    "        plt.imshow(array_to_img(image))\n",
    "    plt.title(f\"{title_prefix}Original Image\")\n",
    "    \n",
    "    # M√°scara verdadeira\n",
    "    plt.subplot(1, num_cols, 2)\n",
    "    display_target(true_mask)\n",
    "    plt.title(f\"{title_prefix}True Mask\")\n",
    "    \n",
    "    # Predi√ß√£o (se fornecida)\n",
    "    if pred_mask is not None:\n",
    "        plt.subplot(1, num_cols, 3)\n",
    "        display_mask(pred_mask)\n",
    "        plt.title procurou\"{title_prefix}Predicted Mask\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso:\n",
    "# compare_segmentation(val_input_imgs[0], val_targets[0], pred_mask)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
